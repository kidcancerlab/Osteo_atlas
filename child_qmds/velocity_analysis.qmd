We are interested in how cell types and states in each sample change are evolving based on splicing dynamics. For this purpose will perform velocity analysis.

## New velocity analysis function

I realized that I should have just created individual loom files for the filtered_feature matrices, that way I can subset by any barcodes that I want. So i'm going to rewrite the r_make_loom_files function.

Input is a table with the following column names:
    -sample_id
    -h5_path
    -bam_path
    -species

```{r}
velo_input <- read.table("misc/allsample_details.txt",
                         header = TRUE) %>%
    dplyr::select(sample_id = sample_name,
                  species,
                  data_source) %>%
    mutate(data_path = paste0(
            recode(data_source,
                   "GEO" = "/home/gdrobertslab/lab/Counts_2/",
                    "NCH" = "/home/gdrobertslab/lab/Counts_2/",
                    "SJ" = "/home/gdrobertslab/lab/ExternalData/Patel_lab/",
                    "NCI_POB" = "/home/gdrobertslab/lab/ExternalData/McEachron_lab/"))) %>%
    unique()
rownames(velo_input) <- NULL

h5s <- ifelse(velo_input$data_source == "NCI_POB",
                             paste0(velo_input$data_path,
                                    "03_FilteredMatricesH5/",
                                    velo_input$sample_id,
                                    "_filtered_feature_bc_matrix.h5"),
                             paste0(velo_input$data_path,
                                    velo_input$sample_id,
                                    "/filtered_feature_bc_matrix.h5"))

velo_input$h5_path <- h5s

ext_data_path <- "/home/gdrobertslab/lab/ExternalData/"

bams <-
    ifelse(
           velo_input$data_source %in% c("NCH", "GEO"),
           paste0("/home/gdrobertslab/lab/Counts_2/",
                  velo_input$sample_id,
                  "/possorted_genome_bam.bam"),
           ifelse(
                  velo_input$data_source == "NCI_POB",
                  paste0(ext_data_path,
                         "McEachron_lab/BAMs/",
                         velo_input$sample_id,
                         "_gex_possorted_bam.bam"),
                  paste0(ext_data_path,
                         "Patel_lab/",
                         velo_input$sample_id,
                         "/possorted_genome_bam.bam")
                         )
                         )

#bams from multiomic runs have different names
bams <- ifelse(file.exists(bams),
                   bams,
                   gsub("possorted_genome", "gex_possorted", bams))

velo_input$bam_path <- bams


#rewrite species to match list in make loom function
unique(velo_input$species)
velo_input$species <- recode(velo_input$species,
       "patient" = "human",
       "xenograft" = "mixed",
       "mousemodel" = "mouse")

#new_function is new_make_loom_files
#install my version of rrrSingleCellUtils
# devtools::install("/home/gdrobertslab/lab/Analysis/MattGust/projects/rrrSingleCellUtils")

r_make_loom_files(input_table = velo_input,
                    out_dir = "loom_output/samples",
                    cluster_account = "gdrobertslab")

#Need to do it for dog samples since they aren't in allsamples_details right now
dog_samps <- read.table("/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/misc/allsample_details.txt",
                        header = TRUE) %>%
    dplyr::select(sample_id = sample_name,
                  species,
                  data_source) %>%
    subset(species == "canine") %>%
    mutate(data_path =
            recode(data_source,
                   "CSU" = "/home/gdrobertslab/lab/ExternalData/Regan_lab/",
                   "NCH" = "/home/gdrobertslab/lab/Counts_2/",
                   "TU" = "/home/gdrobertslab/lab/ExternalData/Gardner/",
                   "UoM" = "/home/gdrobertslab/lab/ExternalData/Modiano_Lab/Counts/")) %>%
    mutate(h5_path =
            recode(data_source,
                   "NCH" = paste0(data_path,
                                  sample_id,
                                  "/filtered_feature_bc_matrix.h5"),
                   "CSU" = paste0(data_path,
                                  sample_id,
                                  "/filtered_feature_bc_matrix.h5"),
                   "TU" = paste0(data_path,
                                 sample_id,
                                 "/filtered_feature_bc_matrix.h5"),
                   "UoM" = paste0(data_path,
                                  sample_id,
                                  "/filtered_feature_bc_matrix.h5"
                                  ))) %>%
    mutate(bam_path =
           recode(data_source,
                  "NCH" = paste0(data_path,
                                 sample_id,
                                 "/gex_possorted_bam.bam"),
                  "CSU" = paste0(data_path,
                                 sample_id,
                                 "/",
                                 sample_id,
                                 "_possorted_genome_bam.bam"),
                  "TU" = paste0(data_path,
                                sample_id,
                                "/possorted_genome_bam.bam"),
                  "UoM" = paste0(data_path,
                                 sample_id,
                                 "/possorted_genome_bam.bam"
                                 )))

#Fix wrong bam file for one of the NCH samples
dog_samps[dog_samps$sample_id == "S0032", ]$bam_path <-
    "/home/gdrobertslab/lab/Counts_2/S0032/possorted_genome_bam.bam"

#Fix dan's weird sample names in h5_paths
missing_h5 <- !file.exists(dog_samps$h5_path)
dog_samps[missing_h5, ]$h5_path <-
    paste0(dog_samps[missing_h5, ]$data_path,
           dog_samps[missing_h5, ]$sample_id,
           "/",
           dog_samps[missing_h5, ]$sample_id,
           "_filtered_feature_bc_matrix.h5")
all(file.exists(dog_samps$h5_path) & file.exists(dog_samps$bam_path))

dog_samps$gtf_path <- "/home/gdrobertslab/lab/GenRef/10x-canine-atlas_arc/genes/genes.gtf.gz"

loom_paths <- paste0("loom_output/samples/", dog_samps$sample_id, "/", dog_samps$sample_id, ".loom")
loom_paths[!file.exists(loom_paths)]

r_make_loom_files(input_table = dog_samps,
                  out_dir = "loom_output/samples",
                  cluster_account = "gdrobertslab")
```

## Write off Metadata for Velocity Analysis

In order to analyze the data, we need to save a table of cell-level metadata, including barcodes, seurat clusters, and annotations.

First we need to read in our objects for this. The most up to date object seems to change frequently, but as of 2/19 at 3:15 pm i'm using the ojbects in tumor_vs_stroma.

```{r}
yogi_prefix <- "/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/"
obj_names <- list.files(paste0(yogi_prefix, "output/seurat_objects/tumor_vs_stroma"))
#get only fdl files
obj_names <- str_replace_all(obj_names[grep("fdl", obj_names)],
                             ".qs",
                             "")

obj_list <- list()
for (ob_name in obj_names) {
    obj_list[[ob_name]] <-
        qs::qread(paste0("/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/output/seurat_objects/tumor_vs_stroma/", ob_name, ".qs"))
}
```

```{r write-off-md}
lapply(names(obj_list), function(obj_name) {
    write_off_md(sobj = obj_list[[obj_name]],
                 id_col = "sample_name",
                 output_dir = paste0("loom_output/metadata/",
                                     obj_name),
                 vars_to_keep = c("sample_name",
                                  "seurat_clusters",
                                  "Ann_level1",
                                  "Ann_level2",
                                  "Ann_level3"),
                 handle_n_of_1 = FALSE)
})
```

## Analyze .loom Files

First I need to activate my conda environment. I set `eval = FALSE` because the environment path will change based on who is rendering this file.

```{bash activate-env, eval = FALSE}
conda activate /home/gdrobertslab/mjg015/R/x86_64-pc-linux-gnu-library/4.3/rrrSingleCellUtils/r_rna_velo
```

Next I need to import my conda libraries.

```{python load-py-libs}
import anndata
import scvelo as scv
import pandas as pd
import numpy as np
import matplotlib as plt
import scanpy as sc
import os
import re
```

### mm_mets_cancer_cells

```{python analyze-mm-mets-cancer-cells}
#get names of loom files
merged_ad = loom_to_an(obj_name = "mm_mets_cancer_cells",
                       loom_dir = "loom_output/samples",
                       metadata_dir = "loom_output/metadata/")

dog_list=["dogs_prim_cancer_cells_fdl", "dogs_prim_normal_cells_fdl", "dogs_mets_cancer_cells_fdl", "dogs_mets_normal_cells_fdl"]
ob_names = os.listdir("loom_output/metadata")
ob_names = [x for x in ob_names if x not in dog_list]
ob_names = [x for x in ob_names if x not in ["patient_mets_cancer_cells_fdl", "patient_prim_cancer_cells_fdl", "xeno_mets_human_fdl"]]

for ob in ob_names:
    print("Processing " + ob)
    merged_ad = loom_to_an(obj_name = ob,
                           loom_dir = "loom_output/samples",
                           metadata_dir = "loom_output/metadata")
    print("Created " + ob + "successfully")
    calc_velo(merged_ad)
    #save anndata object so you don't have to remake them
    merged_ad.write(filename = "loom_output/anndata/" + ob + ".ad")
    print("Calculated velocity for and saved off " + ob)


#     scv.tl.velocity_graph(merged_ad, backend = "threading")
#     #create plots
#     scv.pl.velocity_embedding_stream(merged_ad, basis = "umap", color = "seurat_clusters", show = False, save = "scvelo/" + ob + "_umap_clusters.png", dpi = 300)
#     #optionally create fdl plot
#     if len(merged_ad.obsm["X_fdl"]) == 2:
#         scv.pl.velocity_embedding_stream(merged_ad, basis = "fdl", color = "seurat_clusters", show = False, save = "scvelo/" + ob + "_fdl_clusters.png", dpi = 300)



def write_ob_and_plots(ob):
    print("starting on " + ob)
    merged_ad=loom_to_an(obj_name = ob,
                     loom_dir = "loom_output/samples",
                     metadata_dir = "loom_output/metadata")
    print("made " + ob + " , now calculating velocity")
    calc_velo(merged_ad)
    merged_ad.write(filename = "loom_output/anndata/" + ob + ".ad")
    print("calculated velocity and saved off " + ob)
    #make the plots and save them off
    scv.tl.velocity_graph(merged_ad, backend = "threading")
    #seurat clusters in umap space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "umap",
                                     color = "seurat_clusters",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_clusters.png")
    #Ann_Level3 in umap space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "umap",
                                     color = "Ann_Level3",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_annotations.png")
    #Seurat clusters in fdl space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "fdl",
                                     color = "seurat_clusters",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_clusters.png")
    #Ann_Level3 in fdl space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "fdl",
                                     color = "Ann_Level3",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_annotations.png")
    return(obj_name + "_parallel")


#trying parallel stuff
from multiprocessing import Pool
with Pool(processes = 6) as pool:
    output = pool.map(write_ob_and_plots, ob_names)


#with Pool(processes = args.processes) as pool:
    # output = pool.map(process_lines, chr_list
```