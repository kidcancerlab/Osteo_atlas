We are interested in how cell types and states in each sample change are evolving based on splicing dynamics. For this purpose will perform velocity analysis.

## New velocity analysis function

I realized that I should have just created individual loom files for the filtered_feature matrices, that way I can subset by any barcodes that I want. So i'm going to rewrite the r_make_loom_files function.

Input is a table with the following column names:
    -sample_id
    -h5_path
    -bam_path
    -species

```{r}
velo_input <- read.table("misc/allsample_details.txt",
                         header = TRUE) %>%
    dplyr::select(sample_id = sample_name,
                  species,
                  data_source) %>%
    mutate(data_path = paste0(
            recode(data_source,
                   "GEO" = "/home/gdrobertslab/lab/Counts_2/",
                   "NCH" = "/home/gdrobertslab/lab/Counts_2/",
                   "SJ" = "/home/gdrobertslab/lab/ExternalData/Patel_lab/",
                   "NCI_POB" = "/home/gdrobertslab/lab/ExternalData/McEachron_lab/",
                   "CSU" = "/home/gdrobertslab/lab/ExternalData/Regan_lab/",
                   "TU" = "/home/gdrobertslab/lab/ExternalData/Gardner/",
                   "UoM" = "/home/gdrobertslab/lab/ExternalData/Modiano_Lab/Counts/"))) %>%
    unique() %>%
    mutate(#add h5 paths
           h5_path = ifelse(data_source == "NCI_POB",
                            paste0(data_path,
                                   "03_FilteredMatricesH5/",
                                   sample_id,
                                   "_filtered_feature_bc_matrix.h5"),
                            paste0(data_path,
                                   sample_id,
                                   "/filtered_feature_bc_matrix.h5")),
           #add bam paths
           bam_path = ifelse(data_source == "NCI_POB",
                             paste0(data_path,
                                    "BAMs/",
                                    sample_id,
                                    "_gex_possorted_bam.bam"),
                             ifelse(data_source == "CSU",
                                    paste0(data_path,
                                           sample_id,
                                           "/",
                                           sample_id,
                                           "_possorted_genome_bam.bam"),
                                    paste0(data_path,
                                           sample_id,
                                           "/possorted_genome_bam.bam"))),
           gtf_path = recode(species,
                             "canine" = "/home/gdrobertslab/lab/GenRef/10x-canine-atlas_arc/genes/genes.gtf.gz",
                             "mousemodel" = "/home/gdrobertslab/lab/GenRef/10x-mm10_arc/genes/genes.gtf.gz",
                             "patient" = "/home/gdrobertslab/lab/GenRef/10x-hg38_arc/genes/genes.gtf.gz",
                             "xenograft" = "/home/gdrobertslab/lab/GenRef/10x-hg38-mm10_arc/genes/genes.gtf.gz"))
#fix edge cases for h5's (subset of dan regan's objects) and bams (subset of nch ones)
velo_input$h5_path[!file.exists(velo_input$h5_path)] <-
    paste0(velo_input$data_path,
          velo_input$sample_id,
          "/",
          velo_input$sample_id,
          "_possorted_genome_bam.bam")[!file.exists(velo_input$h5_path)]
velo_input$bam_path[!file.exists(velo_input$bam_path)] <-
    paste0(velo_input$data_path,
           velo_input$sample_id,
           "/gex_possorted_bam.bam")[!file.exists(velo_input$bam_path)]

all(file.exists(velo_input$h5_path) & file.exists(velo_input$bam_path))

rownames(velo_input) <- NULL

loom_paths <- paste0("loom_output/samples/", velo_input$sample_id, "/", velo_input$sample_id, ".loom")
loom_paths[!file.exists(loom_paths)]

velo_input <- velo_input[!file.exists(loom_paths), ]

r_make_loom_files(input_table = velo_input,
                  out_dir = "loom_output/samples",
                  cluster_account = "gdrobertslab")
```

## Write off Metadata for Velocity Analysis

In order to analyze the data, we need to save a table of cell-level metadata, including barcodes, seurat clusters, and annotations.

First we need to read in our objects for this. The most up to date object seems to change frequently, but as of 2/19 at 3:15 pm i'm using the ojbects in tumor_vs_stroma.

```{r}
yogi_prefix <- "/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/"
obj_names <- list.files(paste0(yogi_prefix, "output/seurat_objects/tumor_vs_stroma"))
#get only fdl files
obj_names <- str_replace_all(obj_names[grep("fdl", obj_names)],
                             ".qs",
                             "")

obj_list <- list()
for (ob_name in obj_names) {
    obj_list[[ob_name]] <-
        qs::qread(paste0("/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/output/seurat_objects/tumor_vs_stroma/", ob_name, ".qs"))
}
```

```{r write-off-md}
lapply(names(obj_list), function(obj_name) {
    write_off_md(sobj = obj_list[[obj_name]],
                 id_col = "sample_name",
                 output_dir = paste0("loom_output/metadata/",
                                     obj_name),
                 vars_to_keep = c("sample_name",
                                  "seurat_clusters",
                                  "Ann_level1",
                                  "Ann_level2",
                                  "Ann_level3"),
                 handle_n_of_1 = FALSE)
})
```

## Analyze .loom Files

First I need to activate my conda environment. I set `eval = FALSE` because the environment path will change based on who is rendering this file.

```{bash activate-env, eval = FALSE}
conda activate /home/gdrobertslab/mjg015/R/x86_64-pc-linux-gnu-library/4.3/rrrSingleCellUtils/r_rna_velo
```

Next I need to import my conda libraries.

```{python load-py-libs}
import anndata
import scvelo as scv
import pandas as pd
import numpy as np
import matplotlib as plt
import scanpy as sc
import os
import re
```

### mm_mets_cancer_cells

```{python analyze-mm-mets-cancer-cells}
#get names of loom files
merged_ad = loom_to_an(obj_name = "mm_mets_cancer_cells",
                       loom_dir = "loom_output/samples",
                       metadata_dir = "loom_output/metadata/")

dog_list=["dogs_prim_cancer_cells_fdl", "dogs_prim_normal_cells_fdl", "dogs_mets_cancer_cells_fdl", "dogs_mets_normal_cells_fdl"]
ob_names = os.listdir("loom_output/metadata")
ob_names = [x for x in ob_names if x not in dog_list]
ob_names = [x for x in ob_names if x not in ["patient_mets_cancer_cells_fdl", "patient_prim_cancer_cells_fdl", "xeno_mets_human_fdl"]]

for ob in ob_names:
    print("Processing " + ob)
    merged_ad = loom_to_an(obj_name = ob,
                           loom_dir = "loom_output/samples",
                           metadata_dir = "loom_output/metadata")
    print("Created " + ob + "successfully")
    calc_velo(merged_ad)
    #save anndata object so you don't have to remake them
    merged_ad.write(filename = "loom_output/anndata/" + ob + ".ad")
    print("Calculated velocity for and saved off " + ob)


#     scv.tl.velocity_graph(merged_ad, backend = "threading")
#     #create plots
#     scv.pl.velocity_embedding_stream(merged_ad, basis = "umap", color = "seurat_clusters", show = False, save = "scvelo/" + ob + "_umap_clusters.png", dpi = 300)
#     #optionally create fdl plot
#     if len(merged_ad.obsm["X_fdl"]) == 2:
#         scv.pl.velocity_embedding_stream(merged_ad, basis = "fdl", color = "seurat_clusters", show = False, save = "scvelo/" + ob + "_fdl_clusters.png", dpi = 300)



def write_ob_and_plots(ob):
    print("starting on " + ob)
    merged_ad=loom_to_an(obj_name = ob,
                     loom_dir = "loom_output/samples",
                     metadata_dir = "loom_output/metadata")
    print("made " + ob + " , now calculating velocity")
    calc_velo(merged_ad)
    merged_ad.write(filename = "loom_output/anndata/" + ob + ".ad")
    print("calculated velocity and saved off " + ob)
    #make the plots and save them off
    scv.tl.velocity_graph(merged_ad, backend = "threading")
    #seurat clusters in umap space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "umap",
                                     color = "seurat_clusters",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_clusters.png")
    #Ann_Level3 in umap space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "umap",
                                     color = "Ann_Level3",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_annotations.png")
    #Seurat clusters in fdl space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "fdl",
                                     color = "seurat_clusters",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_clusters.png")
    #Ann_Level3 in fdl space
    scv.pl.velocity_embedding_stream(merged_ad,
                                     basis = "fdl",
                                     color = "Ann_Level3",
                                     show = False,
                                     save = "scvelo/" + ob + "_umap_annotations.png")
    return(obj_name + "_parallel")


#trying parallel stuff
from multiprocessing import Pool
with Pool(processes = 6) as pool:
    output = pool.map(write_ob_and_plots, ob_names)


#with Pool(processes = args.processes) as pool:
    # output = pool.map(process_lines, chr_list
```