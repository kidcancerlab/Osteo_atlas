We are interested in how cell types and states in each sample change are evolving based on splicing dynamics. For this purpose will perform velocity analysis.

## New velocity analysis function

I realized that I should have just created individual loom files for the filtered_feature matrices, that way I can subset by any barcodes that I want. So i'm going to rewrite the r_make_loom_files function.

Input is a table with the following column names:
    -sample_id
    -h5_path
    -bam_path
    -species

```{r}
velo_input <- read.table("misc/allsample_details.txt",
                         header = TRUE) %>%
    dplyr::select(sample_id = sample_name,
                  species,
                  data_source) %>%
    mutate(data_path = paste0(
            recode(data_source,
                   "GEO" = "/home/gdrobertslab/lab/Counts_2/",
                    "NCH" = "/home/gdrobertslab/lab/Counts_2/",
                    "SJ" = "/home/gdrobertslab/lab/ExternalData/Patel_lab/",
                    "NCI_POB" = "/home/gdrobertslab/lab/ExternalData/McEachron_lab/"))) %>%
    unique()
rownames(velo_input) <- NULL

h5s <- ifelse(velo_input$data_source == "NCI_POB",
                             paste0(velo_input$data_path,
                                    "03_FilteredMatricesH5/",
                                    velo_input$sample_id,
                                    "_filtered_feature_bc_matrix.h5"),
                             paste0(velo_input$data_path,
                                    velo_input$sample_id,
                                    "/filtered_feature_bc_matrix.h5"))

velo_input$h5_path <- h5s

ext_data_path <- "/home/gdrobertslab/lab/ExternalData/"

bams <-
    ifelse(
           velo_input$data_source %in% c("NCH", "GEO"),
           paste0("/home/gdrobertslab/lab/Counts_2/",
                  velo_input$sample_id,
                  "/possorted_genome_bam.bam"),
           ifelse(
                  velo_input$data_source == "NCI_POB",
                  paste0(ext_data_path,
                         "McEachron_lab/BAMs/",
                         velo_input$sample_id,
                         "_gex_possorted_bam.bam"),
                  paste0(ext_data_path,
                         "Patel_lab/",
                         velo_input$sample_id,
                         "/possorted_genome_bam.bam")
                         )
                         )

#bams from multiomic runs have different names
bams <- ifelse(file.exists(bams),
                   bams,
                   gsub("possorted_genome", "gex_possorted", bams))

velo_input$bam_path <- bams


#rewrite species to match list in make loom function
unique(velo_input$species)
velo_input$species <- recode(velo_input$species,
       "patient" = "human",
       "xenograft" = "mixed",
       "mousemodel" = "mouse")

#new_function is new_make_loom_files
#install my version of rrrSingleCellUtils
# devtools::install("/home/gdrobertslab/lab/Analysis/MattGust/projects/rrrSingleCellUtils")

r_make_loom_files(input_table = velo_input,
                    out_dir = "loom_output/samples",
                    cluster_account = "gdrobertslab")

#Need to do it for dog samples since they aren't in allsamples_details right now
dog_samps <- read.table("/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/misc/allsample_details.txt",
                        header = TRUE) %>%
    dplyr::select(sample_id = sample_name,
                  species,
                  data_source) %>%
    subset(species == "canine") %>%
    mutate(data_path =
            recode(data_source,
                   "CSU" = "/home/gdrobertslab/lab/ExternalData/Regan_lab/",
                   "NCH" = "/home/gdrobertslab/lab/Counts_2/",
                   "TU" = "/home/gdrobertslab/lab/ExternalData/Gardner/",
                   "UoM" = "/home/gdrobertslab/lab/ExternalData/Modiano_Lab/Counts/")) %>%
    mutate(h5_path =
            recode(data_source,
                   "NCH" = paste0(data_path,
                                  sample_id,
                                  "/filtered_feature_bc_matrix.h5"),
                   "CSU" = paste0(data_path,
                                  sample_id,
                                  "/filtered_feature_bc_matrix.h5"),
                   "TU" = paste0(data_path,
                                 sample_id,
                                 "/filtered_feature_bc_matrix.h5"),
                   "UoM" = paste0(data_path,
                                  sample_id,
                                  "/filtered_feature_bc_matrix.h5"
                                  ))) %>%
    mutate(bam_path =
           recode(data_source,
                  "NCH" = paste0(data_path,
                                 sample_id,
                                 "/gex_possorted_bam.bam"),
                  "CSU" = paste0(data_path,
                                 sample_id,
                                 "/",
                                 sample_id,
                                 "_possorted_genome_bam.bam"),
                  "TU" = paste0(data_path,
                                sample_id,
                                "/possorted_genome_bam.bam"),
                  "UoM" = paste0(data_path,
                                 sample_id,
                                 "/possorted_genome_bam.bam"
                                 )))

#Fix wrong bam file for one of the NCH samples
dog_samps[dog_samps$sample_id == "S0032", ]$bam_path <-
    "/home/gdrobertslab/lab/Counts_2/S0032/possorted_genome_bam.bam"

#Fix dan's weird sample names in h5_paths
missing_h5 <- !file.exists(dog_samps$h5_path)
dog_samps[missing_h5, ]$h5_path <-
    paste0(dog_samps[missing_h5, ]$data_path,
           dog_samps[missing_h5, ]$sample_id,
           "/",
           dog_samps[missing_h5, ]$sample_id,
           "_filtered_feature_bc_matrix.h5")
all(file.exists(dog_samps$h5_path) & file.exists(dog_samps$bam_path))

dog_samps$gtf_path <- "/home/gdrobertslab/lab/GenRef/10x-canine-atlas_arc/genes/genes.gtf.gz"

loom_paths <- paste0("loom_output/samples/", dog_samps$sample_id, "/", dog_samps$sample_id, ".loom")
loom_paths[!file.exists(loom_paths)]

r_make_loom_files(input_table = dog_samps,
                  out_dir = "loom_output/samples",
                  cluster_account = "gdrobertslab")
```

## Write off Metadata for Velocity Analysis

In order to analyze the data, we need to save a table of cell-level metadata, including barcodes, seurat clusters, and annotations.

First we need to read in our objects for this. The most up to date object seems to change frequently, but as of 2/19 at 3:15 pm i'm using the ojbects in tumor_vs_stroma.

```{r}
yogi_prefix <- "/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/"
obj_names <- list.files(paste0(yogi_prefix, "output/seurat_objects/final_tumor_vs_stroma"))
#get only fdl files
obj_names <- str_replace_all(obj_names, ".qs", "")

obj_list <- list()
for (ob_name in obj_names) {
    obj_list[[ob_name]] <-
        qs::qread(paste0("/home/gdrobertslab/lab/Analysis/Yogesh/CellTypeAnnRefs/output/seurat_objects/final_tumor_vs_stroma/", ob_name, ".qs"))
}
```

```{r write-off-md}
lapply(names(obj_list), function(obj_name) {
    write_off_md(sobj = obj_list[[obj_name]],
                 id_col = "sample_name",
                 output_dir = paste0("loom_output/metadata/",
                                     obj_name),
                 vars_to_keep = c("sample_name",
                                  "seurat_clusters",
                                  "Ann_Level1",
                                  "Ann_Level2",
                                  "Ann_Level3"),
                 handle_n_of_1 = FALSE)
})
```

## Analyze .loom Files

First I need to activate my conda environment. I set `eval = FALSE` because the environment path will change based on who is rendering this file.

```{bash activate-env, eval = FALSE}
conda activate /home/gdrobertslab/mjg015/R/x86_64-pc-linux-gnu-library/4.3/rrrSingleCellUtils/r_rna_velo
```

Next I need to import my conda libraries.

```{python load-py-libs}
import anndata
import scvelo as scv
import pandas as pd
import numpy as np
import matplotlib as plt
import matplotlib.pyplot as pyplot
import scanpy as sc
import os
import re
```

### mm_mets_cancer_cells

```{python analyze-mm-mets-cancer-cells}
#get names of loom files
merged_ad = loom_to_an(obj_name = "mm_mets_cancer_cells",
                       loom_dir = "loom_output/samples",
                       metadata_dir = "loom_output/metadata/")

dog_list=["dogs_prim_cancer_cells_fdl", "dogs_prim_normal_cells_fdl", "dogs_mets_cancer_cells_fdl", "dogs_mets_normal_cells_fdl"]
ob_names = os.listdir("loom_output/metadata")
ob_names = [x for x in ob_names if x not in dog_list]

ob_names = ["xeno_prim_human_fdl", "mm_prim_cancer_cells_fdl", "mm_mets_cancer_cells_fdl"]

for ob in ob_names:
    print("Processing " + ob)
    merged_ad = loom_to_an(obj_name = ob,
                           loom_dir = "loom_output/samples",
                           metadata_dir = "loom_output/metadata")
    print("Created " + ob + "successfully")
    calc_velo(merged_ad)
    #save anndata object so you don't have to remake them
    merged_ad.write(filename = "loom_output/anndata/" + ob + ".ad")
    print("Calculated velocity for and saved off " + ob)


#     scv.tl.velocity_graph(merged_ad, backend = "threading")
#     #create plots
#     scv.pl.velocity_embedding_stream(merged_ad, basis = "umap", color = "seurat_clusters", show = False, save = "scvelo/" + ob + "_umap_clusters.png", dpi = 300)
#     #optionally create fdl plot
#     if len(merged_ad.obsm["X_fdl"]) == 2:
#         scv.pl.velocity_embedding_stream(merged_ad, basis = "fdl", color = "seurat_clusters", show = False, save = "scvelo/" + ob + "_fdl_clusters.png", dpi = 300)



def write_ob(ob):
    print("starting on " + ob)
    merged_ad=loom_to_an(obj_name = ob,
                     loom_dir = "loom_output/samples",
                     metadata_dir = "loom_output/metadata")
    print("made " + ob + " , now calculating velocity")
    calc_velo(merged_ad)
    scv.tl.velocity_graph(merged_ad, backend = "threading", n_jobs = 40)
    merged_ad.write(filename = "loom_output/anndata/" + ob + ".ad")



#I realized the objects I created don't have Ann_Levels present, so I need to add those and create the additional plots

ob_names = os.listdir("loom_output/metadata")
ob_names = list(filter(lambda x:'fdl' not in x, ob_names))
ob_names[1]

def add_ann_level(ob_name):
    if os.path.exists("loom_output/anndata/" + ob_name + ".ad"):
        print("reading in " + ob_name)
        ad = anndata.read("loom_output/anndata/" + ob_name + ".ad")
        #read in all metadata files
        md_files = os.listdir("loom_output/metadata/" + ob_name)
        md_list = []
        for one_md in md_files:
            print(one_md + " for " + ob_name)
            #get sample id from file name
            sample_id = re.sub("_metadata.csv", "", one_md)
            #read in md 
            filt_md = pd.read_csv("loom_output/metadata/" + ob_name + "/" + one_md, index_col = "CellID").reindex(ad.obs.index).dropna()
            md_list.append(filt_md)
        merged_md = pd.concat(md_list)
        #remove all columns that contain embeddings
        tmp=~merged_md.columns.str.contains("(harmony)|(PC)|(umap)", na = False)
        merged_md = merged_md[merged_md.columns[tmp.astype("bool")]]
        #remove columns already present in object
        merged_md = merged_md.filter(merged_md.columns.difference(ad.obs.columns))
        ad.obs=ad.obs.merge(merged_md, how = "outer", left_index = True, right_index = True)
        ad.write(filename = "loom_output/anndata/" + ob_name + ".ad")
        return(ob_name + "_ann_levels")


for ob in ob_names:
    add_ann_level(ob)


#make plots and save them off
ob_names = os.listdir("loom_output/anndata")
ob_names = list(filter(lambda x:'fdl' not in x, ob_names))
ob_names = [x.replace(".ad", "") for x in ob_names]

def save_plots(ob):
    ad_ob = anndata.read("loom_output/anndata/" + ob + ".ad")
    scv.tl.velocity_graph(ad_ob, backend = "threading", n_jobs = 30)
    scv.pl.velocity_embedding_stream(ad_ob,
                                     basis = "umap",
                                     color = "seurat_clusters",
                                     show = False,
                                     save = ob + "_umap_clusters.png")
    # #Ann_Level3 in umap space
    # scv.pl.velocity_embedding_stream(ad_ob,
    #                                  basis = "umap",
    #                                  color = "Ann_Level3",
    #                                  show = False,
    #                                  save = ob + "_umap_annotations.png")
    # #Seurat clusters in fdl space
    # scv.pl.velocity_embedding_stream(ad_ob,
    #                                     basis = "fdl",
    #                                     color = "seurat_clusters",
    #                                     show = False,
    #                                     save = ob + "_fdl_clusters.png")
    # # #Ann_Level3 in fdl space
    # scv.pl.velocity_embedding_stream(ad_ob,
    #                                     basis = "fdl",
    #                                     color = "Ann_Level3",
    #                                     show = False,
    #                                     save = ob + "_fdl_annotations.png")


#trying to fix the mistake i made by adding metadata to objects made from fdl folder
def fix_everything(ob):
    #first read in correct anndata object
    ad = anndata.read("loom_output/anndata/" + ob + ".ad")
    #read in metadata again
    md_files = os.listdir("loom_output/metadata/" + ob)
    md_list = []
    for one_md in md_files:
        print(one_md + " for " + ob)
        sample_id = re.sub("_metadata.csv", "", one_md)
        filt_md = pd.read_csv("loom_output/metadata/" + ob + "/" + one_md, index_col = "bc").reindex(ad.obs.index).dropna()
        md_list.append(filt_md)
    merged_md = pd.concat(md_list)
    merged_md["seurat_clusters"] = pd.Categorical(merged_md["seurat_clusters"])
    ad.obs = merged_md.reindex(ad.obs.index)
    ad.obsm["X_umap"] = merged_md.filter(regex = "umap_").reindex(ad.obs.index).to_numpy()
    scv.tl.velocity_graph(ad, backend = "threading", n_jobs = 36)
    ad.write("loom_output/anndata/" + ob + ".ad")
    scv.pl.velocity_embedding_stream(ad,
                                     basis = "umap",
                                     color = "Ann_Level3",
                                     show = False,
                                     save = ob + "_umap_annotations.png")
    scv.pl.velocity_embedding_stream(ad,
                                     basis = "umap",
                                     color = "seurat_clusters",
                                     show = False,
                                     save = ob + "_umap_clusters.png")

#only doing mouse models and patient samples for now
ob_names = ["patient_mets_normal_cells", "patient_mets_cancer_cells", "patient_prim_normal_cells", "patient_prim_cancer_cells", "mm_mets_normal_cells", "mm_prim_cancer_cells"]


for ob in ob_names:
    fix_everything(ob)


```